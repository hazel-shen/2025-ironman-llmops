# Day 32 - LoRA è‡ªå»ºå†è¨“ç·´ Demo (Qwen2.5)

ğŸ“š æœ¬å°ˆæ¡ˆç‚º 2025 iThome éµäººè³½ - LLMOps ç³»åˆ— Day 32 çš„å®Œæ•´ç¨‹å¼ç¢¼

## ğŸ¯ Demo èªªæ˜

æœ¬å°ˆæ¡ˆç¤ºç¯„å¦‚ä½•å°‡ Day 23 çš„çŸ¥è­˜åº« (kb.jsonl) è½‰æ›æˆè¨“ç·´/é©—è­‰è³‡æ–™é›†ï¼Œä¸¦åˆ©ç”¨ `LoRA (Low-Rank Adaptation)` åœ¨æœ¬æ©Ÿ (Mac M3/CPU/GPU) æˆ– `Colab` ä¸Šå° `Qwen2.5-1.5B-Instruct` é€²è¡Œè¼•é‡åŒ–å¾®èª¿ï¼Œè®“æ¨¡å‹å­¸æœƒï¼š

- âœ… ä»¥ä¼æ¥­èªæ°£å›ç­” FAQ
- âœ… å¼•ç”¨çŸ¥è­˜åº«è¦ç¯„ (ä¾æ“šå…¬å¸è¦ç¯„: ...)
- âœ… æ²’æœ‰ä¾æ“šæ™‚ç¦®è²Œæ‹’ç­”
- âœ… æ­é…ã€Œè¦å‰‡å¾Œè™•ç†ã€æå‡æº–ç¢ºç‡è‡³ 90%+

M3 ç´„ 40 åˆ†é˜å³å¯å®Œæˆï¼Œä¸éœ€ä¸Šå‚³è³‡æ–™åˆ°é›²ç«¯ã€‚

## ğŸ“ å°ˆæ¡ˆçµæ§‹

```
day32_lora_on_premise/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ kb.jsonl               # çŸ¥è­˜åº« (Day 23 è¤‡è£½)
â”‚   â”œâ”€â”€ train_qwen_v1.jsonl    # è¨“ç·´é›† (ç”± KB ç”Ÿæˆ)
â”‚   â””â”€â”€ eval_qwen_v1.jsonl     # é©—è­‰é›† (æ³›åŒ–æ¸¬è©¦)
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ diagnose_errors.py          # (Optional) Day33 ç”¨çš„è…³æœ¬ï¼Œæ‹¿ä¾†è·‘éå…¨éƒ¨çš„é©—è­‰é›†ï¼ŒçŸ¥é“æ¨¡å‹çš„å¼±é»å•å¥åœ¨å“ª
â”‚   â”œâ”€â”€ fix_remaining_issues.py     # (Optional) Day33 ç”¨çš„è…³æœ¬ï¼Œæ‹¿ä¾†å°ç—‡ä¸‹è—¥ï¼Œè®“è¨“ç·´é›†æœ‰æ›´å¤šç²¾æº–çš„æå•
â”‚   â”œâ”€â”€ generate_qwen_train_set.py  # æ­¥é©Ÿ 1: ç”Ÿæˆè¨“ç·´é›†
â”‚   â”œâ”€â”€ generate_qwen_eval_set.py   # æ­¥é©Ÿ 1: ç”Ÿæˆé©—è­‰é›†
â”‚   â”œâ”€â”€ train_qwen_lora.py          # æ­¥é©Ÿ 2: åŸ·è¡Œ LoRA å¾®èª¿
â”‚   â””â”€â”€ test_qwen_lora.py           # æ­¥é©Ÿ 3: æ¸¬è©¦ + å¾Œè™•ç†
â”œâ”€â”€ environment.yaml           # Conda ç’°å¢ƒ
â””â”€â”€ README.md
```

## ğŸš€ å¿«é€Ÿé–‹å§‹ (5 æ­¥é©Ÿ)

### æ­¥é©Ÿ 0: å®‰è£ç’°å¢ƒ

```bash
# Conda
conda env create -f environment.yaml
conda activate day32_lora_on_premise

# æˆ– pip
pip install torch transformers peft accelerate datasets safetensors
```

### æ­¥é©Ÿ 1: æº–å‚™è³‡æ–™

```bash
# è¤‡è£½çŸ¥è­˜åº«
cp ../day23_iteration/data/kb.jsonl data/

# ç”Ÿæˆè¨“ç·´/é©—è­‰é›†
python scripts/generate_qwen_train_set.py
python scripts/generate_qwen_eval_set.py
```

### æ­¥é©Ÿ 2: è¨“ç·´æ¨¡å‹

```bash
python scripts/train_qwen_lora.py
# M3 24GB: 30-40 åˆ†é˜
# Colab T4: 8-12 åˆ†é˜
```

### æ­¥é©Ÿ 3: æ¸¬è©¦æ•ˆæœ

```bash
â¯ python scripts/test_qwen_lora.py
======================================================================
ğŸ§ª Qwen2.5-1.5B-Instruct å¾®èª¿æ¨¡å‹æ¸¬è©¦ (å¸¶ä¾†æºæ¨™æ³¨)
======================================================================

ğŸ“‚ è¼‰å…¥æ¸¬è©¦è³‡æ–™...
âœ“ è¼‰å…¥çŸ¥è­˜åº«ï¼š15 æ¢

ğŸ¤– è¼‰å…¥æ¨¡å‹...
  åŸºç¤æ¨¡å‹ï¼šQwen/Qwen2.5-1.5B-Instruct
  LoRA æ¬Šé‡ï¼š./qwen_lora_output/final_model
âœ“ æ¨¡å‹è¼‰å…¥å®Œæˆ
âš¡ å¿«é€Ÿæ¸¬è©¦æ¨¡å¼ï¼šåªæ¸¬è©¦å‰ 20 æ¢
----------------------------------------------------------------------
Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)

[ç¯„ä¾‹ 1] ğŸ“š KB_MATCH
â“ å•é¡Œï¼švpn é€£ç·šé€¾æ™‚...
âœ“ æœŸæœ›ï¼šä¾æ“šå…¬å¸è¦ç¯„:2025 å¹´ VPN è¨­å®šæµç¨‹ï¼šæ­¥é©Ÿ 1 ä¸‹è¼‰æ–°ç‰ˆå®¢æˆ¶ç«¯ï¼Œæ­¥é©Ÿ 2 ä½¿ç”¨ SSO ç™»å…¥ã€‚...
ğŸ’¬ æ¨¡å‹ï¼šä¾æ“šå…¬å¸è¦ç¯„:2025 å¹´ VPN è¨­å®šæµç¨‹ï¼šæ­¥é©Ÿ 1 ä¸‹è¼‰æ–°ç‰ˆå®¢æˆ¶ç«¯ï¼Œæ­¥é©Ÿ 2 ä½¿ç”¨ SSO ç™»å…¥ã€‚...
ğŸ“Š ç›¸ä¼¼åº¦ï¼š100.0%
ğŸ” ä¾†æºï¼šçŸ¥è­˜åº« doc_611a2e74 åŒ¹é…åº¦ 92.6%
```

### æ­¥é©Ÿ 4: (Optional) è¨»å†Šåˆ° Registry

```bash
tar -czf qwen-lora-v1.tar.gz -C qwen_lora_output final_model/
```

## ğŸ“Š å¯¦é©—æˆæœ

- è¨“ç·´é›† 299 ç­† / é©—è­‰é›† 85 ç­†
- ç´”æ¨¡å‹å¹³å‡ç›¸ä¼¼åº¦ï¼š78%
- åŠ ä¸Šè¦å‰‡å¾Œè™•ç†ï¼š92%+
- å¸¸è¦‹èª¤å·®ï¼šVPN vs MFA æ··æ·†ï¼Œå†’è™Ÿæ ¼å¼ä¸ä¸€è‡´ã€æœªçŸ¥å•é¡Œç„¡æ³•æ‹’ç­”ï¼ŒDay33 æœƒè§£é‡‹å¦‚ä½•è™•ç†

## ğŸ› å¸¸è¦‹å•é¡Œ

**Q: è¨˜æ†¶é«”ä¸è¶³?**  
é™ä½ `per_device_train_batch_size`ï¼Œæˆ–æ”¹ç”¨ Colab GPUã€‚

## ğŸ“š å»¶ä¼¸é–±è®€

| Day    | ä¸»é¡Œ                                                                     | è§£æ±ºå•é¡Œ            | æœ¬ç¯‡æ•´åˆ         |
| ------ | ------------------------------------------------------------------------ | ------------------- | ---------------- |
| Day 20 | [å“è³ªç›£æ§](https://ithelp.ithome.com.tw/articles/10393293)               | åµæ¸¬å¹»è¦º            | âœ… ç›¸ä¼¼åº¦é©—è­‰    |
| Day 22 | [Model Registry](https://ithelp.ithome.com.tw/articles/10394144)         | ç‰ˆæœ¬ç®¡ç†            | âœ… LoRA ç‰ˆæœ¬è¨»å†Š |
| Day 23 | [RAG å¢é‡ Ã— Fine-tuning](https://ithelp.ithome.com.tw/articles/10394515) | çŸ¥è­˜æ›´æ–° + èªæ°£çµ±ä¸€ | âœ… 80% å ´æ™¯æ–¹æ¡ˆ  |
