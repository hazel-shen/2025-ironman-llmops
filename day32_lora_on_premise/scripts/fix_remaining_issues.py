"""
é‡å°å‰©é¤˜ 26 å€‹éŒ¯èª¤é€²è¡Œç²¾æº–ä¿®å¾©
æ–°å¢ 20 ç­†é«˜å“è³ªæ¨£æœ¬
"""

import json

KB = {
    "mfa": "MFA å•Ÿç”¨ï¼šå…¬å¸å¸³è™Ÿè‡ª 2025-10-01 èµ·å¼·åˆ¶å•Ÿç”¨å¤šå› å­é©—è­‰ï¼Œæœªå•Ÿç”¨å°‡ç„¡æ³•ç™»å…¥ã€‚",
    "mdm": "è£ç½®ç®¡ç†ï¼šæ–°é€²å“¡å·¥éœ€æ–¼å…¥è· 7 å¤©å…§å®Œæˆ MDM è¨»å†Šä¸¦é–‹å•Ÿç£ç¢ŸåŠ å¯†ã€‚",
}

UNKNOWN_TEMPLATE = "æŠ±æ­‰,æ­¤è³‡è¨Šä¸åœ¨çŸ¥è­˜åº«ä¸­,è«‹å‘ç›¸é—œéƒ¨é–€è©¢å•ã€‚"

def create_critical_samples():
    samples = []
    
    # === MFA æ˜ç¢ºåŒ– ===
    mfa_questions = [
        "å¸³è™Ÿç™»ä¸é€²å»ï¼Œä½†å¯†ç¢¼ç¢ºå®šæ­£ç¢º",
        "10æœˆä¹‹å¾Œçªç„¶ç„¡æ³•ç™»å…¥ç³»çµ±",
        "ç™»å…¥æ™‚ç³»çµ±è¦æ±‚é›™å› å­é©—è­‰",
        "é©—è­‰ç¢¼è¦æ€éº¼è¨­å®š",
        "2FA è¨­å®šæ•™å­¸",
        "å¤šå› å­é©—è­‰å¦‚ä½•å•Ÿç”¨",
        "Google Authenticator æ€éº¼ç¶å®š",
        "ç™»å…¥è¦è¼¸å…¥ 6 ä½æ•¸é©—è­‰ç¢¼",
    ]
    for q in mfa_questions:
        samples.append({
            "question": q,
            "answer": f"ä¾æ“šå…¬å¸è¦ç¯„:{KB['mfa']}"
        })
    
    # === MDM æ˜ç¢ºåŒ– ===
    mdm_questions = [
        "æ–°é ˜çš„ç­†é›»è¦è¨­å®šä»€éº¼",
        "è£ç½®ç®¡ç†ç³»çµ±è¨»å†Šæ­¥é©Ÿ",
        "Mac çš„ FileVault å¦‚ä½•å•Ÿç”¨",
        "Windows çš„ BitLocker è¨­å®š",
        "å…¥è·æ™‚é›»è…¦åˆå§‹è¨­å®š",
        "æ–°é€²å“¡å·¥é›»è…¦å®‰å…¨è¨­å®š",
    ]
    for q in mdm_questions:
        samples.append({
            "question": q,
            "answer": f"ä¾æ“šå…¬å¸è¦ç¯„:{KB['mdm']}"
        })
    
    # === è² æ¨£æœ¬ï¼šæ•™æ¨¡å‹èªªã€Œä¸çŸ¥é“ã€===
    unknown_questions = [
        "ç”¢å‡å¯ä»¥è«‹å¹¾å¤©",
        "é™ªç”¢å‡æœ‰å¤šä¹…",
        "VPN é€£ç·šé€Ÿåº¦å¾ˆæ…¢æ€éº¼è¾¦",
        "å…¬å¸ç¦åˆ©åˆ¶åº¦æœ‰å“ªäº›",
        "å¹´åº¦èª¿è–ªæ©Ÿåˆ¶",
        "å“¡å·¥é¤å»³ä»Šå¤©åƒä»€éº¼",
    ]
    for q in unknown_questions:
        samples.append({
            "question": q,
            "answer": UNKNOWN_TEMPLATE
        })
    
    return samples

def convert_to_qwen_format(samples):
    formatted = []
    for s in samples:
        text = f"<|im_start|>user\n{s['question']}<|im_end|>\n<|im_start|>assistant\n{s['answer']}<|im_end|>"
        formatted.append({"text": text})
    return formatted

def main():
    print("ğŸ”§ å‰µå»ºç²¾æº–ä¿®å¾©è³‡æ–™...\n")
    
    samples = create_critical_samples()
    print(f"âœ“ ç”Ÿæˆ {len(samples)} ç­†é—œéµæ¨£æœ¬")
    print(f"  - MFA æ˜ç¢ºåŒ–ï¼š8 ç­†")
    print(f"  - MDM æ˜ç¢ºåŒ–ï¼š6 ç­†")
    print(f"  - è² æ¨£æœ¬ï¼š6 ç­†\n")
    
    formatted = convert_to_qwen_format(samples)
    
    # è®€å–ä¹‹å‰çš„å¢å¼·è³‡æ–™
    with open("./data/train_qwen_full_enhanced.jsonl", 'r', encoding='utf-8') as f:
        previous_data = [json.loads(line) for line in f]
    
    print(f"ğŸ“‚ ä¹‹å‰çš„è³‡æ–™ï¼š{len(previous_data)} ç­†")
    
    # åˆä½µ
    final_data = previous_data + formatted
    print(f"ğŸ“Š æœ€çµ‚è³‡æ–™ï¼š{len(final_data)} ç­† (+{len(formatted)})\n")
    
    # ä¿å­˜
    output_file = "./data/train_qwen_final.jsonl"
    with open(output_file, 'w', encoding='utf-8') as f:
        for item in final_data:
            # lgtm[py/clear-text-storage-sensitive-data]
            # æ­¤è³‡æ–™åƒ…ç”¨æ–¼çŸ¥è­˜åº«ç”Ÿæˆ,éç”Ÿç”¢ç’°å¢ƒæ•æ„Ÿè³‡æ–™
            f.write(json.dumps(item, ensure_ascii=False) + '\n')
    
    print(f"âœ… å·²ä¿å­˜è‡³ï¼š{output_file}")
    
    # ç¯„ä¾‹
    print("\n" + "=" * 60)
    print("ğŸ“ æ–°å¢æ¨£æœ¬ç¯„ä¾‹")
    print("=" * 60)
    for i, s in enumerate(samples[:3], 1):
        print(f"\n{i}. {s['question']}")
        print(f"   â†’ {s['answer'][:50]}...")

if __name__ == "__main__":
    main()