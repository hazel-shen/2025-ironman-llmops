# LLM Cache Demo

æœ€å°å¯è¡Œçš„ LLM å¿«å– Demoï¼ŒåŒ…å«ï¼š

- Prompt å­—ä¸²å¿«å–ï¼ˆRedisï¼‰
- èªæ„å¿«å–ï¼ˆEmbedding Cacheï¼›æ”¯æ´ Redis æŒä¹…åŒ–ï¼‰
- æŒ‡æ¨™æ”¶é›†ï¼ˆPrometheus `/metrics` èˆ‡ `/metrics/json`ï¼‰
- FastAPI æœå‹™ï¼š`/ask`, `/health`

## ğŸš€ å¿«é€Ÿé–‹å§‹

### 0) å•Ÿå‹• Redis

```bash
# 1. å»ºç«‹è³‡æ–™å¤¾ï¼ˆé¿å…æ¬Šé™å•é¡Œï¼‰
mkdir -p ./data/redis

# 2. å•Ÿå‹• Redis
docker compose up -d

# 3. æ¸¬è©¦
redis-cli ping   # å› PONG

# 4. çµæŸæ¸¬è©¦å¾Œ shut down ä¸¦æ¸…é™¤ volume
docker compose down -v
```

### 1) å»ºç«‹ä¸¦å•Ÿå‹• Conda ç’°å¢ƒ

```bash
conda env create -f environment.yaml
conda activate day21_cache

# åœç”¨ç’°å¢ƒ
conda deactivate

# æŸ¥çœ‹æ‰€æœ‰ç’°å¢ƒ
conda env list

# åˆªé™¤ç’°å¢ƒï¼ˆâš ï¸ æ…ç”¨ï¼‰
conda env remove -n day21_cache

# æ›´æ–°ç’°å¢ƒï¼ˆç•¶ environment.yml æœ‰ä¿®æ”¹æ™‚ï¼‰
conda env update -f environment.yml --prune
```

### 2) è¨­å®šç’°å¢ƒè®Šæ•¸

```bash
cp .env.example .env
# ç·¨è¼¯ .envï¼ŒæŠŠä½ çš„ OPENAI_API_KEY å¡«å…¥
```

### 3) å•Ÿå‹• API

```bash
uvicorn api.main:app --reload
```

### 4) æ¸¬è©¦ API

```bash
# å•ä¸€æ¬¡ â†’ LLM çœŸå¯¦å›ç­”ï¼Œä¸¦å­˜é€² Prompt Cache + Embed Cache
curl -X POST localhost:8000/ask -H "content-type: application/json" -d '{"question":"ä»€éº¼æ˜¯å¿«å–ï¼Ÿ"}'

# å†å•é¡ä¼¼å•é¡Œ â†’ å¯å‘½ä¸­å¿«å–
curl -X POST localhost:8000/ask -H "content-type: application/json" -d '{"question":"è«‹è§£é‡‹å¿«å–æ˜¯ä»€éº¼"}'

# æª¢æŸ¥å¥åº·ç‹€æ…‹
curl localhost:8000/health

# æª¢æŸ¥æŒ‡æ¨™ï¼ˆPrometheus æ ¼å¼ï¼‰
curl localhost:8000/metrics

# æª¢æŸ¥æŒ‡æ¨™ï¼ˆJSON æ ¼å¼ï¼‰
curl localhost:8000/metrics/json
```

## ğŸ§ª æ¸¬è©¦ï¼ˆpytestï¼‰

å°ˆæ¡ˆé™„å¸¶æ¸¬è©¦ï¼Œæ¶µè“‹ APIã€å¿«å–èˆ‡ Metricsã€‚
æ¸¬è©¦å·² mock OpenAIï¼ˆä¸æœƒå°å¤–å‘¼å«ã€ä¸èŠ±éŒ¢ï¼‰ï¼Œä¸¦æœƒåœ¨æ¯æ¬¡åŸ·è¡Œå‰å¾Œè‡ªå‹•æ¸…ç©º Redisã€‚

### 1) å®‰è£ç›¸ä¾ (Optional, Conda å·²ç¶“åŒ…é€²å»)

```bash
pip install -U pytest pytest-asyncio httpx pytest-cov
```

### 2) åŸ·è¡Œæ¸¬è©¦

```bash
# å…¨éƒ¨æ¸¬è©¦
pytest -vv

# æŒ‡å®šå–®ä¸€æª”æ¡ˆ
pytest -vv tests/test_api.py
```

### 3)æ¸¬è©¦ç‰¹é»

- ä¸ç”¨å•Ÿå‹• uvicornï¼Œhttpx ç›´æ¥ä»¥ in-process å‘¼å« FastAPI appã€‚
- Redis æ¯å€‹æ¸¬è©¦ç¨ç«‹é€£ç·šã€æ¸¬å‰å¾Œ flushdb()ï¼Œé¿å…æ±¡æŸ“ã€‚
- Mock LLMï¼šchat èˆ‡ embed å›ºå®šå›å‚³å‡è³‡æ–™ï¼Œé¿å…å¤–éƒ¨ APIã€‚
- Metrics æ¸¬è©¦æœƒé©—è­‰ /metrics èˆ‡ /metrics/json æ­£ç¢ºæ›´æ–°ã€‚

## ğŸ”§ ç®¡ç† Redis å¿«å–

åœ¨é€™å€‹å°ˆæ¡ˆè£¡ï¼Œæˆ‘å€‘æŠŠ Prompt Cache å’Œ Embedding Cache éƒ½å­˜åœ¨ Redisã€‚
æœ‰æ™‚å€™éœ€è¦æ¸…æ‰è³‡æ–™ä¾†æ¸¬è©¦å‘½ä¸­ç‡æˆ–é‡ç½®ç’°å¢ƒï¼Œå¯ä»¥ç”¨ä»¥ä¸‹å¹¾ç¨®æ–¹å¼ï¼š

1. æ¸…ç©ºæ•´å€‹ Redis

```bash
âš ï¸ æœƒåˆªæ‰æ‰€æœ‰è³‡æ–™ï¼ˆåŒ…å« prompt / embed cache ç­‰ï¼‰ï¼š

redis-cli FLUSHDB     # æ¸…é™¤ç•¶å‰è³‡æ–™åº« (é è¨­ DB 0)
redis-cli FLUSHALL    # æ¸…é™¤æ‰€æœ‰è³‡æ–™åº«
```

2. åªæ¸…é™¤ç‰¹å®šå¿«å–

å¦‚æœåªæƒ³æ¸…é™¤æŸé¡ cacheï¼Œå¯ä»¥ç”¨ key patternï¼š

```
# æ¸…é™¤ Prompt Cache
redis-cli --scan --pattern "prompt_cache:*" | xargs redis-cli DEL

# æ¸…é™¤ Embedding Cache
redis-cli --scan --pattern "embed_cache:*" | xargs redis-cli DEL
```

## ğŸ“‚ å°ˆæ¡ˆçµæ§‹

```yaml
day21_cache/
.
â”œâ”€â”€ README.md                # å°ˆæ¡ˆèªªæ˜æ–‡ä»¶
â”œâ”€â”€ __init__.py              # æ¨™è¨˜æ ¹ç›®éŒ„ç‚º Python packageï¼ˆé€šå¸¸ç©ºç™½å³å¯ï¼‰
â”‚
â”œâ”€â”€ api/                     # API å±¤ï¼ˆFastAPI / RESTful å…¥å£ï¼‰
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py              # API ä¸»å…¥å£ï¼ˆå•Ÿå‹• FastAPI appï¼‰
â”‚   â””â”€â”€ routers/             # å„åŠŸèƒ½çš„è·¯ç”±æ‹†åˆ†ï¼ˆex: /health, /cacheï¼‰
â”‚
â”œâ”€â”€ core/                    # æ ¸å¿ƒè¨­å®šèˆ‡å…±ç”¨é‚è¼¯
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py            # ç’°å¢ƒè®Šæ•¸ & è¨­å®šç®¡ç†
â”‚   â””â”€â”€ metrics.py           # ç›£æ§ & æŒ‡æ¨™ï¼ˆPrometheus/Grafanaï¼‰
â”‚
â”œâ”€â”€ data/                    # è³‡æ–™ç›¸é—œ
â”‚   â””â”€â”€ redis/               # Redis è³‡æ–™å­˜æ”¾å€ï¼ˆå¯èƒ½æ›è¼‰ volumeï¼‰
â”‚
â”œâ”€â”€ docker-compose.yml       # Docker Compose å®šç¾©ï¼ˆRedis, API ç­‰æœå‹™ï¼‰
â”œâ”€â”€ environment.yaml         # Conda ç’°å¢ƒè¨­å®šæª”
â”‚
â”œâ”€â”€ models/                  # è³‡æ–™æ¨¡å‹
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ schemas.py           # Pydantic schemaï¼ˆå®šç¾© API è¼¸å…¥è¼¸å‡ºï¼‰
â”‚
â”œâ”€â”€ pytest.ini               # pytest è¨­å®š
â”‚
â”œâ”€â”€ scripts/                 # å·¥å…·è…³æœ¬
â”‚   â””â”€â”€ init_index.py        # åˆå§‹åŒ–ç´¢å¼•ï¼ˆex: å»ºç«‹ Redis/å‘é‡åº« indexï¼‰
â”‚
â”œâ”€â”€ services/                # æœå‹™å±¤ï¼ˆå°è£å•†æ¥­é‚è¼¯ï¼‰
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ cache.py             # Prompt/å›æ‡‰å¿«å–
â”‚   â”œâ”€â”€ embed_cache_redis.py # Embedding Cache with Redis
â”‚   â”œâ”€â”€ llm.py               # èˆ‡ LLM API äº’å‹•ï¼ˆOpenAI / Anthropicï¼‰
â”‚   â””â”€â”€ redis_client.py      # Redis å®¢æˆ¶ç«¯é€£ç·šå°è£
â”‚
â””â”€â”€ tests/                   # æ¸¬è©¦
    â”œâ”€â”€ conftest.py          # pytest å…±ç”¨è¨­å®š/fixture
    â”œâ”€â”€ test_api.py          # æ¸¬ API è¡Œç‚º
    â”œâ”€â”€ test_embed_cache_redis.py # æ¸¬è©¦ embedding cache
    â”œâ”€â”€ test_health.py       # å¥åº·æª¢æŸ¥ endpoint æ¸¬è©¦
    â”œâ”€â”€ test_metrics.py      # æ¸¬è©¦ metrics è¼¸å‡º
    â””â”€â”€ test_prompt_cache.py # æ¸¬è©¦ prompt cache åŸºæœ¬åŠŸèƒ½
```

## ğŸ”§ å¸¸è¦‹èª¿æ•´

- `core/config.py` â†’ å¯èª¿æ•´ `CACHE_TTL`, `EMBED_SIM_THRESHOLD`
- `.env` â†’ è¨­å®š `OPENAI_API_KEY`
- èªæ„å¿«å–ï¼šç›®å‰æ”¯æ´ `Redis`ï¼ˆæŒä¹…åŒ–ï¼‰ï¼Œå¤§é‡è³‡æ–™æ™‚å¯æ”¹ç”¨ `FAISS/pgvector`
