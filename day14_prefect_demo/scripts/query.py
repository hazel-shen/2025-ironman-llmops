"""
æœ€å°æª¢ç´¢è…³æœ¬ï¼šè¼‰å…¥ vector_index.jsonï¼Œå°è¼¸å…¥ query åš cosine similarityï¼Œ
å°å‡º Top-K æœ€ç›¸è¿‘çš„ chunkï¼ˆé è¨­ 3 ç­†ï¼‰ã€‚
ç”¨æ³•ï¼š
    python scripts/query.py "åŠ ç­è¦å‰‡"
"""
import json
import math
import sys
from pathlib import Path

INDEX = Path(__file__).resolve().parents[1] / "data" / "vector_index.json"

def l2_norm(v):
    return math.sqrt(sum(x*x for x in v)) or 1.0

def cosine(a, b):
    # å‡è¨­çš†å·² L2 normalizeï¼›è‹¥ç„¡ï¼Œé€™è£¡ä¿éšªå†é™¤ä¸€æ¬¡
    an, bn = l2_norm(a), l2_norm(b)
    return sum(x*y for x, y in zip(a, b)) / (an * bn)

def fake_embed(text: str):
    # èˆ‡ utils.embeddings çš„å‡å‘é‡ä¸€è‡´åŽŸç†ï¼šç°¡å–® hash -> 8 ç¶­
    h = abs(hash(text))
    v = [((h >> (i*8)) & 0xFF) / 255.0 for i in range(8)]
    n = l2_norm(v)
    return [x / n for x in v]

def main():
    if len(sys.argv) < 2:
        print(__doc__)
        sys.exit(0)

    query = sys.argv[1]
    if not INDEX.exists():
        print(f"Index not found: {INDEX}. è«‹å…ˆåŸ·è¡Œ daily_pipeline ç”¢ç”Ÿç´¢å¼•ã€‚")
        sys.exit(1)

    data = json.loads(INDEX.read_text(encoding="utf-8"))
    items = data.get("items", [])
    if not items:
        print("Index empty.")
        sys.exit(1)

    # é€™è£¡ç”¨å‡å‘é‡æŸ¥è©¢ï¼ˆè‹¥ä½ ç”¨çœŸå¯¦ OpenAI å‘é‡ï¼Œè«‹æ”¹ç‚ºç›¸åŒæ¨¡åž‹ç”Ÿæˆï¼‰
    q_vec = fake_embed(query)

    scored = []
    for it in items:
        v = it["vector"]
        score = cosine(q_vec, v)
        scored.append((score, it["chunk"], it["id"]))

    scored.sort(key=lambda x: x[0], reverse=True)
    topk = scored[:3]

    print(f"\nðŸ”Ž Query: {query}\n")
    for rank, (score, chunk, cid) in enumerate(topk, start=1):
        print(f"[{rank}] score={score:.4f} | id={cid}\n{chunk}\n")

if __name__ == "__main__":
    main()
