# step3_query_answer.py
import json
import numpy as np
import faiss
from pathlib import Path
from utils_openai import embed, chat_answer

INDEX_DIR = Path("index")

def load_index_and_meta():
    index = faiss.read_index(str(INDEX_DIR / "faiss.index"))
    meta = json.loads((INDEX_DIR / "meta.json").read_text(encoding="utf-8"))
    return index, meta

def retrieve_top_k(index, query_vec, k=1):
    query_mat = np.array([query_vec], dtype="float32")
    D, I = index.search(query_mat, k)
    return D[0], I[0]  # è·é›¢ã€ç´¢å¼•

def main():
    query = "æˆ‘è¦æ€éº¼è«‹å‡ï¼Ÿ" #TODO:: è«‹ä¿®æ”¹é€™è£¡

    # 1) è¼‰å…¥ç´¢å¼•+æ–‡ä»¶
    index, meta = load_index_and_meta()
    docs = meta["docs"]

    # 2) æŸ¥è©¢å‘é‡
    q_vec = np.array(embed(query), dtype="float32")

    # 3) æª¢ç´¢
    D, I = retrieve_top_k(index, q_vec, k=1)
    context = docs[I[0]]
    print("ğŸ” æœ€ç›¸é—œæ–‡ä»¶ï¼š", context)

    # 4) è®“ LLM ç”Ÿæˆç­”æ¡ˆ
    system_prompt = "ä½ æ˜¯ä¸€å€‹ä¼æ¥­ FAQ åŠ©ç†ã€‚è«‹æ ¹æ“šæä¾›çš„çŸ¥è­˜åº«å…§å®¹å›ç­”ä½¿ç”¨è€…å•é¡Œï¼Œè‹¥çŸ¥è­˜åº«æœªæ¶µè“‹è«‹èªªæ˜ä¸çŸ¥é“ã€‚"
    user_prompt = f"æ ¹æ“šä»¥ä¸‹çŸ¥è­˜åº«å…§å®¹å›ç­”ï¼š\n{context}\n\nå•é¡Œï¼š{query}"

    # 5) æŠŠå…©å€‹ prompt æ‰“å°å‡ºä¾†
    print("\n===== System Prompt =====")
    print(system_prompt)
    print("\n===== User Prompt =====")
    print(user_prompt)

    answer = chat_answer(system_prompt, user_prompt)
    print("\nğŸ§  ç­”æ¡ˆï¼š", answer)

if __name__ == "__main__":
    main()
