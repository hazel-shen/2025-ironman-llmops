# retriever_faiss_demo.py
import json
import numpy as np
import faiss
from sentence_transformers import SentenceTransformer
from huggingface_hub import snapshot_download
from tqdm import tqdm
import os

# ----- æ¸¬è©¦è³‡æ–™é›† -----
DOCS = [
    # æ­£ç¢ºç­”æ¡ˆ
    "æœ¬å…¬å¸ç¸½éƒ¨ä½æ–¼å°åŒ—å¸‚ä¿¡ç¾©å€æ¾é«˜è·¯ 11 è™Ÿã€‚",
    # èƒŒæ™¯è³‡è¨Š
    "å…¬å¸å‰µç«‹æ–¼ 2012 å¹´ï¼Œå°ˆæ³¨é›²ç«¯èˆ‡è³‡æ–™æœå‹™ã€‚",
    "æˆ‘å€‘åœ¨æ–°åŠ å¡ã€æ±äº¬èˆ‡èˆŠé‡‘å±±è¨­æœ‰åˆ†å…¬å¸æ“šé»ã€‚",
    # æ··æ·†å¹²æ“¾
    "ç¸½éƒ¨é™„è¿‘äº¤é€šï¼šæ·é‹å¸‚æ”¿åºœç«™æ­¥è¡Œ 5 åˆ†é˜å¯é”ã€‚",
    "ç¸½éƒ¨é™„è¿‘æœ‰ä¸€é–“ Starbucks å’–å•¡å»³ï¼Œå¸¸æœ‰å“¡å·¥èšæœƒã€‚",
    "å…¬å¸æ¯å¹´æœƒåœ¨å°åŒ— 101 èˆ‰è¾¦å¹´æœƒã€‚",
    # ç„¡é—œé›œè¨Š
    "è«‹å‡åˆ¶åº¦ï¼šå“¡å·¥éœ€æå‰ä¸€å¤©ç”³è«‹ï¼Œç·Šæ€¥æƒ…æ³å¯äº‹å¾Œè£œè¾¦ã€‚",
    "å®¢æˆ¶æˆåŠŸéƒ¨é–€è² è²¬å”®å¾Œå°å…¥èˆ‡æ•™è‚²è¨“ç·´ã€‚",
    "å¹´åº¦ç›®æ¨™ï¼šæ‹“å±•æ±å—äºå¸‚å ´ä¸¦å„ªåŒ–è³‡æ–™å¹³å°ã€‚",
]
QUERY = "å…¬å¸çš„ç¸½éƒ¨åœ¨å“ªè£¡ï¼Ÿ"
TOP_K = 5
EMB_MODEL_NAME = "sentence-transformers/all-MiniLM-L6-v2"
OUT_PATH = "candidates.json"
# -------------------

def download_with_progress(model_name: str) -> str:
    """
    ä¸‹è¼‰ HuggingFace æ¨¡å‹ï¼ˆå¸¶ tqdm é€²åº¦æ¢ï¼‰ã€‚
    ç¬¬ä¸€æ¬¡æœƒä¸‹è¼‰ï¼Œä¹‹å¾Œæœƒç›´æ¥ä½¿ç”¨æœ¬åœ°å¿«å–ã€‚
    """
    local_dir = os.path.join("models", model_name.replace("/", "_"))
    if not os.path.exists(local_dir):
        print(f"ğŸ”½ æ­£åœ¨ä¸‹è¼‰æ¨¡å‹: {model_name}")
        snapshot_download(
            repo_id=model_name,
            local_dir=local_dir,
            resume_download=True,
            tqdm_class=tqdm
        )
    else:
        print(f"âœ… å·²æ‰¾åˆ°æœ¬åœ°æ¨¡å‹: {local_dir}")
    return local_dir


if __name__ == "__main__":
    print("ä½¿ç”¨æ¨¡å‹é€²è¡ŒåµŒå…¥ (embedding):", EMB_MODEL_NAME)

    # ç¢ºä¿æ¨¡å‹å­˜åœ¨ï¼ˆæœƒä¸‹è¼‰æˆ–ç›´æ¥è®€æœ¬åœ°ï¼‰
    local_model_path = download_with_progress(EMB_MODEL_NAME)
    embed_model = SentenceTransformer(local_model_path)

    # ----- æ–‡ä»¶èˆ‡æŸ¥è©¢å‘é‡åŒ– -----
    doc_embeds = embed_model.encode(DOCS, convert_to_numpy=True, normalize_embeddings=True)
    q_embed = embed_model.encode([QUERY], convert_to_numpy=True, normalize_embeddings=True)

    # ä½¿ç”¨å…§ç©ï¼ˆnormalize å¾Œç­‰åŒæ–¼ cosine ç›¸ä¼¼åº¦ï¼‰
    dim = doc_embeds.shape[1]
    index = faiss.IndexFlatIP(dim)
    index.add(doc_embeds.astype("float32"))

    D, I = index.search(q_embed.astype("float32"), TOP_K)
    idxs = I[0].tolist()
    scores = D[0].tolist()

    candidates = [
        {"rank": r + 1, "idx": i, "text": DOCS[i], "retriever_score": float(s)}
        for r, (i, s) in enumerate(zip(idxs, scores))
    ]

    print(f"\næŸ¥è©¢ (Query): {QUERY}\n")
    print("=== æª¢ç´¢å™¨ (Retriever) Top-K çµæœï¼ˆæœªé‡æ’ï¼‰===")
    for c in candidates:
        print(f"[R{c['rank']:02d}] åˆ†æ•¸={c['retriever_score']:.4f} | idx={c['idx']} | {c['text']}")

    payload = {"query": QUERY, "candidates": candidates}
    with open(OUT_PATH, "w", encoding="utf-8") as f:
        json.dump(payload, f, ensure_ascii=False, indent=2)

    print(f"\nå·²è¼¸å‡ºå€™é¸çµæœåˆ° {OUT_PATH}ï¼ˆåŒ…å« query èˆ‡ Top-{TOP_K} å€™é¸ï¼‰")
